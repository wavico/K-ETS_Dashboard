#!/usr/bin/env python3
"""
ë°ì´í„° êµ¬ì¡° í™•ì¸ ì„œë¹„ìŠ¤
FastAPIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •ëœ ë²„ì „
"""

import pandas as pd
import os
from pathlib import Path
from typing import Dict, List, Any, Optional

class DataStructureChecker:
    """ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self, data_folder: str = "data"):
        """ì´ˆê¸°í™”"""
        self.data_folder = Path(data_folder)
        self.csv_files = [
            "í™˜ê²½ë¶€ ì˜¨ì‹¤ê°€ìŠ¤ì¢…í•©ì •ë³´ì„¼í„°_êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°°ì¶œëŸ‰_20250103.csv",
            "ë°°ì¶œê¶Œ_ê±°ë˜ë°ì´í„°.csv", 
            "01. 3ì°¨_ì‚¬ì „í• ë‹¹_20250613090824.csv",
            "í•œêµ­ì—ë„ˆì§€ê³µë‹¨_ì‚°ì—…ë¶€ë¬¸ ì—ë„ˆì§€ì‚¬ìš© ë° ì˜¨ì‹¤ê°€ìŠ¤ë°°ì¶œëŸ‰ í†µê³„_20231231.csv"
        ]
    
    def analyze_file_structure(self, filename: str) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ íŒŒì¼ì˜ êµ¬ì¡° ë¶„ì„"""
        filepath = self.data_folder / filename
        if not filepath.exists():
            return None
            
        # ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
        for encoding in ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig']:
            try:
                df = pd.read_csv(filepath, encoding=encoding, low_memory=False)
                
                # ì—°ë„ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
                year_cols = []
                for col in df.columns:
                    col_lower = str(col).lower()
                    if any(pattern in col_lower for pattern in ['ì—°ë„', 'year', 'ë…„ë„', 'ë…„']):
                        year_cols.append(col)
                
                # ë°°ì¶œëŸ‰ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
                emission_cols = []
                for col in df.columns:
                    col_lower = str(col).lower()
                    if any(pattern in col_lower for pattern in ['ë°°ì¶œëŸ‰', 'ë°°ì¶œ', 'emission', 'co2']):
                        emission_cols.append(col)
                
                # ê²°ê³¼ êµ¬ì„±
                result = {
                    "filename": filename,
                    "encoding": encoding,
                    "shape": df.shape,
                    "columns": df.columns.tolist(),
                    "main_columns": df.columns[:10].tolist(),
                    "year_columns": year_cols,
                    "emission_columns": emission_cols[:5],
                    "sample_data": df.head(3).to_dict('records'),
                    "data_types": df.dtypes.to_dict()
                }
                
                # ì—°ë„ ì»¬ëŸ¼ ìƒ˜í”Œ ë°ì´í„°
                if year_cols:
                    year_samples = {}
                    for col in year_cols[:3]:
                        year_samples[col] = df[col].dropna().head(5).tolist()
                    result["year_samples"] = year_samples
                
                return result
                
            except UnicodeDecodeError:
                continue
                
        return None
    
    def check_all_data_structure(self) -> Dict[str, Any]:
        """ëª¨ë“  ë°ì´í„° íŒŒì¼ì˜ êµ¬ì¡° ë¶„ì„"""
        results = {}
        
        for filename in self.csv_files:
            file_result = self.analyze_file_structure(filename)
            if file_result:
                results[filename] = file_result
            else:
                results[filename] = {"error": "ë¡œë“œ ì‹¤íŒ¨"}
        
        return {
            "data_folder": str(self.data_folder),
            "total_files": len(self.csv_files),
            "analyzed_files": len([r for r in results.values() if "error" not in r]),
            "results": results
        }
    
    def get_summary(self) -> Dict[str, Any]:
        """ë°ì´í„° êµ¬ì¡° ìš”ì•½ ì •ë³´"""
        analysis = self.check_all_data_structure()
        
        summary = {
            "total_files": analysis["total_files"],
            "successfully_analyzed": analysis["analyzed_files"],
            "failed_files": analysis["total_files"] - analysis["analyzed_files"],
            "available_columns": {},
            "common_patterns": {
                "year_columns": [],
                "emission_columns": []
            }
        }
        
        # ê³µí†µ ì»¬ëŸ¼ íŒ¨í„´ ì¶”ì¶œ
        all_year_cols = set()
        all_emission_cols = set()
        
        for filename, result in analysis["results"].items():
            if "error" not in result:
                summary["available_columns"][filename] = len(result["columns"])
                all_year_cols.update(result["year_columns"])
                all_emission_cols.update(result["emission_columns"])
        
        summary["common_patterns"]["year_columns"] = list(all_year_cols)
        summary["common_patterns"]["emission_columns"] = list(all_emission_cols)
        
        return summary

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜
def check_data_structure():
    """ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„± ìœ ì§€"""
    checker = DataStructureChecker()
    analysis = checker.check_all_data_structure()
    
    print("ğŸ“Š ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    for filename, result in analysis["results"].items():
        if "error" in result:
            print(f"\nâŒ ë¡œë“œ ì‹¤íŒ¨: {filename}")
            continue
            
        print(f"\nğŸ“ íŒŒì¼: {filename}")
        print("-" * 40)
        print(f"âœ… ì¸ì½”ë”©: {result['encoding']}")
        print(f"   í¬ê¸°: {result['shape']}")
        print(f"   ì»¬ëŸ¼ ìˆ˜: {len(result['columns'])}")
        
        print("   ì£¼ìš” ì»¬ëŸ¼:")
        for i, col in enumerate(result['main_columns']):
            print(f"     {i+1}. {col}")
        
        if result['year_columns']:
            print(f"   ì—°ë„ ê´€ë ¨ ì»¬ëŸ¼: {result['year_columns']}")
            
        if result['emission_columns']:
            print(f"   ë°°ì¶œëŸ‰ ê´€ë ¨ ì»¬ëŸ¼: {result['emission_columns']}")
    
    return analysis

if __name__ == "__main__":
    check_data_structure() 