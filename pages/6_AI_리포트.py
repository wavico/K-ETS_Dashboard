import streamlit as st
import sys
import os
import pdfplumber
from openai import OpenAI
from datetime import datetime
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pinecone import Pinecone, ServerlessSpec
from langchain.embeddings import OpenAIEmbeddings
import uuid
from langchain.chat_models import ChatOpenAI
from io import BytesIO
from docx import Document
from docx.shared import Pt

# ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI_ë¦¬í¬íŠ¸ ìƒì„±ê¸°",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header { font-size: 28px; font-weight: bold; margin-bottom: 20px; }
</style>
""", unsafe_allow_html=True)

# íƒ€ì´í‹€
st.markdown('<h1 class="main-header">ğŸ“„ AI ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„±ê¸°</h1>', unsafe_allow_html=True)

# API í‚¤ ë¡œë”©
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

pinecone_api_key = os.getenv("PINECONE_API_KEY")
index_name = "carbone-index"
pc = Pinecone(api_key=pinecone_api_key)

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
@st.cache_data
def extract_text_from_pdf(uploaded_file):
    with pdfplumber.open(uploaded_file) as pdf:
        text = ""
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

# ëª©ì°¨ ì¶”ì¶œ
def extract_table_of_contents(text):
    prompt = f"""
ë‹¤ìŒ ë¬¸ì„œì—ì„œ **ëª©ì°¨(ì°¨ë¡€)**ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ë§Œ ì •í™•íˆ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.
{text[:4000]}
"""
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ êµ¬ì¡°ì—ì„œ ëª©ì°¨ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” AIì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# ë¬¸ì„œ í˜•ì‹ ìš”ì•½
def summarize_template_structure(text):
    prompt = f"""
ë‹¤ìŒ ë¬¸ì„œì˜ í˜•ì‹(ë³´ê³ ì„œ êµ¬ì¡°, ì œëª© ìŠ¤íƒ€ì¼, êµ¬ì„± íë¦„ ë“±)ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ ì£¼ì„¸ìš”.
{text[:4000]}
"""
    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œ í˜•ì‹ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” AIì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.5
    )
    return response.choices[0].message.content.strip()

# Pinecone ê¸°ë°˜ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
@st.cache_resource
def create_vector_store(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    docs = text_splitter.create_documents([text])
    embeddings_model = OpenAIEmbeddings()
    vectors = embeddings_model.embed_documents([doc.page_content for doc in docs])

    if index_name not in pc.list_indexes().names():
        pc.create_index(
            name=index_name,
            dimension=1536,
            metric="cosine",
            spec=ServerlessSpec(cloud="aws", region="us-east-1")
        )

    index = pc.Index(index_name)
    to_upsert = []
    for i, vector in enumerate(vectors):
        to_upsert.append({
            "id": str(uuid.uuid4()),
            "values": vector,
            "metadata": {"text": docs[i].page_content}
        })
    index.upsert(vectors=to_upsert)
    return index

# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
def retrieve_similar_docs(topic, index, embeddings_model, top_k=5):
    embedded_query = embeddings_model.embed_query(topic)
    result = index.query(vector=embedded_query, top_k=top_k, include_metadata=True)
    return [match["metadata"]["text"] for match in result["matches"]]

# ë³´ê³ ì„œ ìƒì„±
def generate_report_with_rag(topic, index, custom_outline=None):
    llm = ChatOpenAI(temperature=0.7, model_name="gpt-4-turbo")
    embeddings_model = OpenAIEmbeddings()
    docs = retrieve_similar_docs(topic, index, embeddings_model)
    context = "\n\n".join(docs[:5])

    outline_part = f"\në‹¤ìŒ ëª©ì°¨ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”:\n{custom_outline}" if custom_outline else ""

    prompt = f"""
'{topic}'ì— ëŒ€í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- ì°¸ê³  ë¬¸ì„œ ê¸°ë°˜ í˜•ì‹ì„ ë”°ë¥´ë˜, ë³µì‚¬í•˜ì§€ ë§ê³  ìƒˆë¡œìš´ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
ğŸ“š ì°¸ê³  ë¬¸ì„œ:
{context}{outline_part}
"""
    response = llm.invoke(prompt)
    return response.content.strip()

# Word ë¬¸ì„œ ìƒì„±
def generate_docx_report(text, topic):
    doc = Document()
    doc.add_heading(topic, level=1)
    for paragraph in text.split("\n"):
        if paragraph.strip():
            p = doc.add_paragraph(paragraph.strip())
            p.style.font.size = Pt(11)
            p.paragraph_format.line_spacing = 1.5
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ì‚¬ìš©ì ì…ë ¥ ìˆœì„œ
st.subheader("ğŸ“ Step 1: ì£¼ì œ ì…ë ¥")
topic = st.text_input("ë³´ê³ ì„œ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: íƒ„ì†Œì¤‘ë¦½ ì¶”ì§„ ì „ëµ")

st.subheader("ğŸ“ Step 2: í…œí”Œë¦¿ PDF ì—…ë¡œë“œ")
uploaded_file = st.file_uploader("í…œí”Œë¦¿ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

custom_outline = ""
if uploaded_file:
    with st.spinner("ë¬¸ì„œ ë¶„ì„ ì¤‘..."):
        extracted_text = extract_text_from_pdf(uploaded_file)
        toc = extract_table_of_contents(extracted_text)
        structure_summary = summarize_template_structure(extracted_text)
        vector_store = create_vector_store(extracted_text)

    st.subheader("ğŸ“š ë¬¸ì„œ í˜•ì‹ ìš”ì•½")
    st.markdown(structure_summary)

    st.subheader("ğŸ“‘ ì¶”ì¶œëœ í…œí”Œë¦¿ ëª©ì°¨")
    st.code(toc, language="markdown")

    st.subheader("âœï¸ Step 3: ì‚¬ìš©í•  ëª©ì°¨ë¥¼ ìˆ˜ì • ë˜ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©")
    custom_outline = st.text_area("ì‚¬ìš©í•  ëª©ì°¨ë¥¼ ì…ë ¥ ë˜ëŠ” í¸ì§‘í•˜ì„¸ìš”", value=toc, height=200)

# Step 4: ìƒì„± ì‹¤í–‰
if topic and uploaded_file and custom_outline:
    with st.spinner("ğŸ“„ ìƒˆë¡œìš´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        generated_report = generate_report_with_rag(topic, vector_store, custom_outline)
        docx_file = generate_docx_report(generated_report, topic)

    st.success("âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
    st.download_button(
        label="ğŸ“¥ Word í˜•ì‹ìœ¼ë¡œ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (.docx)",
        data=docx_file,
        file_name=f"{topic}_ë³´ê³ ì„œ.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )

    st.text_area("ğŸ“„ ìƒì„±ëœ ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°", generated_report, height=500)
